## 01. 입력벡터로부터 출력벡터 예측하기

instance A Profiling vector ⇒ instance B Profiling vector 값 예측하기

### Anchor instance = g3s.xlarge로 지정

g3s.xlarge ( anchor instance ) ⇒ 'g3.4xlarge', 'g4dn.xlarge', 'g4dn.4xlarge', 'g4dn.16xlarge',  'p2.xlarge', 'p3.2xlarge', 'c5.9xlarge', 'c5.18xlarge'

→ g3s.xlarge 와 각 인스턴스별로 모델이 나와 총 8개의 모델이 완성된다. 

- 가지고있는 데이터셋

    → exp1 : 위의 8개 instance 외 c5.4xlarge 와 g3s.xlarge instance 총 10개 

    → exp2 , exp3 에는 g3s.xlarge 인스턴스의 실험 파일이 없다. 

    → 각 인스턴스 파일안에는 

    cnn 모델 3가지 * dataset 3가지 * batchsize 개수 5개 + 

    rnn 모델도 마찬가지이므로 (*2) == 90 개 csv 파일이 있다. 

[ Anchor instance 를 g3s.xlarge 로 지정할 경우 문제점 ] 

- g3s.xlarge 인스턴스 실험이 exp1에만 있고 target 이 되는 인스턴스는 exp1 , exp2 , exp3 에 모두 있어 실험 개수의 차이가 난다.

    ⇒  g3s.xlarge = 3 ( cnn 개수 ) * 3 ( dataset 개수 ) * 5 ( batch size 수 ) = **45 rows** 

    ⇒ target instance =  3 ( cnn 개수 ) * 3 ( dataset 개수 ) * 5 ( batch size 수 ) * 3 ( exp 의 수 ) = **135 rows**

    g3s.xlarge in exp1 과 g3.4xlarge in exp1 , exp2 , exp3 

    g3s.xlarge exp1  → g3.4xlarge exp1 

    g3s.xlarge exp1 → g3.4xlarge exp2 

    g3s.xlarge exp1 → g3.4xlarge exp3 이렇게 모델링 해야한다. 

- g3s.xlarge 가 비용이 가장 저렴해서 anchor instance 로 지정한 후 모델링을 시도하였으나 사용자에 따라 anchor 을 바꿔야 하는 경우도 있다.

    ⇒ 사용자가 profiling 결과를 가져오는 경우 , 어떤 인스턴스에서 실행한 profiling 결과를 가져왔냐에 따라 바뀔 수 있어야한다. 

- g3s.xlarge 와 g3.4xlarge , g3s.xlarge 와 g4dn.xlarge  이런식으로 짝지어진 추가 데이터셋 파일이 많이 만들어진다.

    ⇒ 이렇게 추가적으로 데이터셋을 많이 만들어낼 필요가 있는가 ? 

### Anchor instance 변경가능하도록

우선 , **cnn 모델** lenet, vggsmall, resnetsmall 세가지를 기준으로 실험해보기 

0 ) Training data 와 Validation data 나누기 

exp1 , exp2 의 실험값으로 training data 를 만들고 exp3 에대해서 validation data로 진행한다면 ? 

⇒ exp1 , exp2 , exp3 실험 결과값이 거의 비슷하므로 정확도는 올라가겠지만 하지만 실제로 모르는 새로운 데이터가 들어올 경우 정확하게 학습을 못한다는 단점이 있다. 

새로운 모델에 대해서도 예측가능하도록 , cnn 모델 3가지 중 2가지에 대하여 학습을 하고 나머지 한가지의 모델에 대해서 validation을 진행하도록 한다. 

Training model 2 가지 = lenet5 , resnetsmall 

Validation model 1 가지 = vggsmall 

- 2600 여개 중 상위 100가지만 뽑아서 벡터생성하자

    columns 의 합이 0 이 아닌 column의 개수가 90개인데 ( exp_name, dataset, model, optimizer, batchsize, instance_name 포함 ) 나머지 10 개에 대해서 어떤 기준으로 columns를 채워야하는가 

    ⇒ 일단은 columns 합이 0 이 아닌 90개로 우선 시도 

    ⇒ 상위 10 개 , 50 개 , 90 개 순서로 시도해보는 방법도 의미있을지 생각해보기 

1 )  Input data 와 target data Labeling 하기 

anchor instance name 과 target instance name 을 입력으로 받고 진행한다.

실험 값이 랜덤으로 저장되어 있기 때문에 input data dataframe , output dataframe 이 같은 워크로드에 대해 알맞게   labeling 되어 있어야 한다. 

- join dataframe

    input < - > target 을 같은 워크로드 기준에 대해 ( model, dataset, batchsize, optimizer ) join 하면 같은 워크로드에 대해 라벨링이 맞게 될 것이라고 생각하여 진행

    ⇒ 라벨링은 맞게 되지만 나중에 모델링 할 때 넣을 값에서 두 값을 다시 나눠야 한다.

    ⇒ column 이 같으면 합쳐질때 'Device_ArgMax_x' ,,'Device_ArgMax_y' 이런 방법으로 되는 것으로 보아 column name 에 '_x'를 포함하면 input , '_y'를 포함하면 target 으로 지정하였다. 

    → 이 방법은 위험요소가 너무 많으므로 방법을 바꾼다. 

- Sort

    ```python
    sort_columns = ['exp_name', 'dataset','model', 'optimizer', 'batchsize']
    sortInput_feature = input_feature.sort_values(sort_columns)
    ```

    값을 sorting 하여 labeling 하면 두 데이터프레임을 join 했다가 나누지 않고도 맞는 labeling을 할 수 있다. 

2 ) Modeling 

Multi-output regression 에서 가능한 많은 알고리즘 다 사용해보기 

- Model 만 고려하여 training 과 test 을 나눈 경우

    1 ) LinearRegression ⇒ prediction 음수값 

    2 ) K-NeighborsRegressor

    3 ) DecisionTreeRegressor

    4 ) RandomForestRegressor 

- Model 과 Dataset 을 함께 고려한 경우

    1 ) LinearRegression 

    2 ) K-NeighborsRegressor

    3 ) DecisionTreeRegressor

    4 ) RandomForestRegressor 

[https://docs.google.com/spreadsheets/d/16V-zERauTxJ7LTGq_N5ToK-VJ4pXEZNxv1Bjy0dsY7Q/edit?usp=sharing](https://docs.google.com/spreadsheets/d/16V-zERauTxJ7LTGq_N5ToK-VJ4pXEZNxv1Bjy0dsY7Q/edit?usp=sharing)

- 오차율 계산 해서 4가지 multi-regressor 방법 중 어떤 방법이 최적인지 확인하기 [ 진행중 ]

    ⇒ 시각적으로는 RandomForest 방법 

[ Resnetsmall 만의 columns ] 

Device_AddN , Device_Conv2D , Device_AddV2 , Device_BroadcastTo , Device_DynamicStitch, Device_Mean , Device_RealDiv , Device__HostRecv, Device_FusedBatchNormGradV3, Device_FusedBatchNormV3

⇒ Resnetsmall 에서만 나타나는 column 으로 인해 prediction 정확도가 내려간다. 

vggsmall 에서는 0 값이지만 resnetsmall 로 학습을 하다보니 prediction 에서 0 이 나와야할 값에 다른 값이 나온다. 

3 ) Validation [ 진행중 ] 

- 오차율 계산

    각 실험마다 나온 벡터들로 어떻게 Error 값을 산출할 것인가? 

### 앞으로 진행할 것들

- 정확한 오차율 계산을 위해 Error 산정하는 방법 파악하기
- Model , dataset , batchsize 까지 기준으로 삼고 Training, Test 나눠서 실험진행해보기

    ⇒ 지금은 vggsmall-fmnist 에 대해서만 실험해보았지만 코드 수정하여 여러 조합으로도 진행해보기

- 상위 10개 , 50개 , 90 개 columns 로 학습하는 방법 진행하기

    ⇒ 각 column 의 합 으로 상위 latency 나누는 방법 혹은 다른방법이 있을지 생각해보기 

- 코드 추상화하기

